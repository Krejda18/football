# player_analysis.py
import streamlit as st
import pandas as pd
import json
import datetime
from pathlib import Path
from typing import Dict, Any, List

from google.oauth2 import service_account
import vertexai
from vertexai.generative_models import GenerativeModel, Content, Part, GenerationConfig

from core_logic import (
    compute_loose_ball_duels, compute_effective_passing_index,
    rating_series, weighted_score, logic_flat_df, breakdown_scores, build_prompt,
    get_positions_for_avg_filter, build_ai_scout_prompt
)

# --- Konfigurace ---
DATA_DIR = Path("./Data")
AVG_DATA_DIR = Path("./AVG - hodnoty")
LOGIC_JSON = Path("metric_logic.json")
LOGO_DIR = Path("./logos")
TOP_CLUBS = ["Slavia Praha", "Sparta Praha", "Viktoria Plze켿"]
COL_POS = "Converted Position"
MIN_MINUTES = 500
SERVICE_ACCOUNT_JSON = "inside-data-story-af484f6c4b69.json"
PROJECT_ID = "inside-data-story"
LOCATION = "us-central1"
MODEL_NAME = "gemini-2.5-pro"

# --- Cachovan칠 funkce ---
def load_and_process_file(file_path: Path) -> pd.DataFrame:
    print(f"--- CACHE MISS: Na캜칤t치m a zpracov치v치m soubor: {file_path.name} ---")
    df = pd.read_excel(file_path, engine="openpyxl")
    df = df[df["Converted Position"] != 'GK']
    df = compute_loose_ball_duels(df)
    df = compute_effective_passing_index(df)
    for col in df.columns:
        if df[col].dtype == 'object':
            df[col] = pd.to_numeric(df[col], errors='ignore')
    return df

@st.cache_data
def get_logic_definition() -> dict:
    with open(LOGIC_JSON, "r", encoding="utf-8") as f:
        return json.load(f)

@st.cache_resource
def initialize_gemini() -> tuple[GenerativeModel | None, bool]:
    """
    Inicializuje model Gemini.
    Pokus칤 se na캜칤st kl칤캜 ze Streamlit Secrets (pro nasazen칤 na cloudu).
    Pokud sel쬰, pokus칤 se na캜칤st kl칤캜 z lok치ln칤ho souboru (pro lok치ln칤 v칳voj).
    """
    creds = None
    try:
        # Pokus 캜. 1: Na캜ten칤 ze Streamlit Secrets (pro Cloud)
        creds_dict = st.secrets["gcp_service_account"]
        creds = service_account.Credentials.from_service_account_info(creds_dict)
        print("--- 칔SP캨CH: Gemini inicializov치n ze Streamlit Secrets. ---")
    except Exception:
        # Pokus 캜. 2: Na캜ten칤 z lok치ln칤ho souboru (pro lok치ln칤 v칳voj)
        print(f"--- Secrets nenalezeny, pokou코칤m se na캜칤st lok치ln칤 soubor: {SERVICE_ACCOUNT_JSON} ---")
        try:
            creds = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_JSON)
            print("--- 칔SP캨CH: Gemini inicializov치n z lok치ln칤ho souboru. ---")
        except Exception as e:
            st.warning(f"Nepoda콏ilo se inicializovat Gemini. Kl칤캜 nenalezen ani v Secrets, ani lok치ln캩. Chyba: {e}")
            return None, False

    # Spole캜n치 inicializace Vertex AI po 칰sp캩코n칠m na캜ten칤 kl칤캜e
    try:
        vertexai.init(project=PROJECT_ID, location=LOCATION, credentials=creds)
        model = GenerativeModel(MODEL_NAME)
        return model, True
    except Exception as e:
        st.warning(f"Poda콏ilo se na캜칤st kl칤캜, ale selhala inicializace Vertex AI: {e}")
        return None, False

@st.cache_data
def load_all_player_data() -> pd.DataFrame:
    all_player_dfs = []
    for file_path in sorted(Path(DATA_DIR).glob("*.xlsx")):
        df = load_and_process_file(file_path)
        df['League'] = file_path.stem
        all_player_dfs.append(df)
    if not all_player_dfs:
        return pd.DataFrame()
    combined_df = pd.concat(all_player_dfs, ignore_index=True)
    return combined_df[combined_df["Minutes played"] >= MIN_MINUTES]


def analyze_player(player_name: str, player_df: pd.DataFrame, avg_df: pd.DataFrame) -> Dict[str, Any]:
    gemini_model, gemini_available = initialize_gemini()
    logic_data = get_logic_definition()
    
    player_rows = player_df[player_df["Player"] == player_name]
    p_avg = player_rows.mean(numeric_only=True)
    main_position = player_rows[COL_POS].iloc[0]

    positions_to_filter = get_positions_for_avg_filter(main_position)
    avg_df_pos_filtered = avg_df[avg_df[COL_POS].isin(positions_to_filter)]
    
    if avg_df_pos_filtered.empty:
        st.warning(f"Pro pozice '{', '.join(positions_to_filter)}' nebyla nalezena 쮂멳n치 srovn치vac칤 data.")
        avg_df_pos_filtered = avg_df

    lg_avg = avg_df_pos_filtered.groupby("Player").mean(numeric_only=True).mean(numeric_only=True)
    
    top_clubs_df = avg_df_pos_filtered[avg_df_pos_filtered["Team"].isin(TOP_CLUBS)]
    if top_clubs_df.empty:
        tp_avg = pd.Series(dtype='float64')
    else:
        tp_avg = top_clubs_df.groupby("Player").mean(numeric_only=True).mean(numeric_only=True)

    rat_lg = rating_series(p_avg, lg_avg)
    rat_tp = rating_series(p_avg, tp_avg)
    
    logic_df = logic_flat_df([main_position], logic_data)
    logic_metrics_in_data = [m for m in logic_df["Metric"] if m in rat_lg.index]

    score_lg = weighted_score(rat_lg[logic_metrics_in_data], logic_df)
    score_tp = weighted_score(rat_tp[logic_metrics_in_data], logic_df)

    sec_lg, sub_lg = breakdown_scores(rat_lg, main_position, logic_data)
    sec_tp, sub_tp = breakdown_scores(rat_tp, main_position, logic_data)
    
    sec_tbl = sec_lg.rename(columns={"Score": "vs. League"}).merge(sec_tp.rename(columns={"Score": "vs. TOP 3"}), on="Section", how="outer")
    sub_tbl = sub_lg.rename(columns={"Score": "vs. League"}).merge(sub_tp.rename(columns={"Score": "vs. TOP 3"}), on=["Section", "Subsection"], how="outer")
    
    GK_METRICS_TO_EXCLUDE = [
        'Clean sheets', 'Conceded goals', 'Conceded goals per 90', 'Exits per 90',
        'Prevented goals', 'Prevented goals per 90', 'Save rate',
        'Shots against', 'Shots against per 90', 'xG against', 'xG against per 90',
        'Back passes received as GK per 90'
    ]
    common_metrics = p_avg.index.intersection(lg_avg.index)
    metrics_to_display = [m for m in common_metrics if m not in GK_METRICS_TO_EXCLUDE]
    rows = []
    for m in sorted(metrics_to_display):
        val_lg = (p_avg.get(m, 0) / lg_avg.get(m, 0) * 100) if lg_avg.get(m, 0) != 0 else pd.NA
        val_tp = (p_avg.get(m, 0) / tp_avg.get(m, 0) * 100) if tp_avg.get(m, 0) != 0 else pd.NA
        rows.append({"Metric": m, "Hr치캜": p_avg.get(m), "Liga 칒": lg_avg.get(m), "TOP Kluby 칒": tp_avg.get(m, pd.NA), "vs. League": val_lg, "vs. TOP 3": val_tp})
    all_metrics_tbl = pd.DataFrame(rows)
    
    analysis_text = "AI anal칳za nen칤 dostupn치."
    if gemini_available and gemini_model:
        try:
            # --- ZM캨NA ZDE: Vol치n칤 nov칠 verze `build_prompt` se spr치vn칳mi daty (tabulkami) ---
            prompt = build_prompt(player_name, [main_position], sec_tbl, sub_tbl, all_metrics_tbl)
            msg = Content(role="user", parts=[Part.from_text(prompt)])
            config = GenerationConfig(max_output_tokens=10000, temperature=0.5, top_k=30)
            response = gemini_model.generate_content([msg], generation_config=config)
            analysis_text = response.text
        except Exception as e:
            analysis_text = f"Do코lo k chyb캩 p콏i generov치n칤 AI anal칳zy: {e}"

    player_row = player_rows.iloc[0]
    player_club = player_row.get("Team", "N/A")
    logo_path = LOGO_DIR / f"{player_club}.png"
    if not logo_path.is_file(): logo_path = None
    
    full_header_block = f"""
    # {player_name}
    ### 游 Z치kladn칤 informace
    **Klub:** {player_club}<br>
    **Pozice:** {main_position}<br>
    **V캩k:** {int(player_row.get('Age', 0))}<br>
    **V칳코ka:** {int(player_row.get('Height', 0))} cm<br>
    **Minuty:** {int(player_row.get('Minutes played', 0))}
    """
    
    return {
        "full_header_block": full_header_block,
        "logo_path": str(logo_path) if logo_path else None,
        "score_lg": score_lg, "score_tp": score_tp,
        "sec_tbl": sec_tbl, "sub_tbl": sub_tbl,
        "all_metrics": all_metrics_tbl,
        "analysis": analysis_text,
        "gemini_available": gemini_available,
    }

# V souboru player_analysis.py

@st.cache_data
def calculate_all_player_metrics_and_ratings(all_players_df: pd.DataFrame, all_avg_df: pd.DataFrame) -> pd.DataFrame:
    logic_data = get_logic_definition()
    results = []
    position_groups = all_players_df[COL_POS].dropna().unique()
    avg_calcs = {}
    
    for pos in position_groups:
        positions_to_filter = get_positions_for_avg_filter(pos)
        avg_df_pos_filtered = all_avg_df[all_avg_df[COL_POS].isin(positions_to_filter)]
        if not avg_df_pos_filtered.empty:
            lg_avg = avg_df_pos_filtered.groupby("Player").mean(numeric_only=True).mean(numeric_only=True)
            top_clubs_df = avg_df_pos_filtered[avg_df_pos_filtered["Team"].isin(TOP_CLUBS)]
            tp_avg = pd.Series(dtype='float64') if top_clubs_df.empty else top_clubs_df.groupby("Player").mean(numeric_only=True).mean(numeric_only=True)
            avg_calcs[pos] = {'lg': lg_avg, 'tp': tp_avg}
    
    for _, player_row in all_players_df.iterrows():
        main_position = player_row[COL_POS]
        if main_position in avg_calcs:
            p_avg, lg_avg, tp_avg = player_row, avg_calcs[main_position]['lg'], avg_calcs[main_position]['tp']
            rat_lg, rat_tp = rating_series(p_avg, lg_avg), rating_series(p_avg, tp_avg)
            logic_df = logic_flat_df([main_position], logic_data)
            logic_metrics_in_data = [m for m in logic_df["Metric"] if m in rat_lg.index]
            score_lg, score_tp = weighted_score(rat_lg[logic_metrics_in_data], logic_df), weighted_score(rat_tp[logic_metrics_in_data], logic_df)
            results.append({
                'Player': player_row['Player'], 'Team': player_row['Team'],
                'League': player_row['League'], 'Position': main_position,
                'Age': player_row['Age'], 'Height': player_row['Height'],
                'Market value': player_row.get('Market value'),
                'Foot': player_row.get('Foot'),
                'Minutes': player_row['Minutes played'],
                'Rating vs Liga': score_lg, 'Rating vs TOP Kluby': score_tp
            })
    
    final_df = pd.DataFrame(results)
    rating_cols = ['Rating vs Liga', 'Rating vs TOP Kluby']
    final_df[rating_cols] = final_df[rating_cols].round(0)
    column_order = ['Player', 'Team', 'League', 'Position', 'Age', 'Height', 'Foot', "Minutes", 'Market value', 'Rating vs Liga', 'Rating vs TOP Kluby']
    return final_df.reindex(columns=column_order)

@st.cache_data
def enrich_data_for_ai_scout(all_players_df: pd.DataFrame, all_avg_df: pd.DataFrame) -> pd.DataFrame:
    logic_data = get_logic_definition()
    enriched_results = []
    position_groups = all_players_df[COL_POS].dropna().unique()
    avg_calcs = {}
    for pos in position_groups:
        positions_to_filter = get_positions_for_avg_filter(pos)
        avg_df_pos_filtered = all_avg_df[all_avg_df[COL_POS].isin(positions_to_filter)]
        if not avg_df_pos_filtered.empty:
            lg_avg = avg_df_pos_filtered.groupby("Player").mean(numeric_only=True).mean(numeric_only=True)
            top_clubs_df = avg_df_pos_filtered[avg_df_pos_filtered["Team"].isin(TOP_CLUBS)]
            tp_avg = pd.Series(dtype='float64') if top_clubs_df.empty else top_clubs_df.groupby("Player").mean(numeric_only=True).mean(numeric_only=True)
            avg_calcs[pos] = {'lg': lg_avg, 'tp': tp_avg}
    for _, player_row in all_players_df.iterrows():
        main_position = player_row[COL_POS]
        if main_position in avg_calcs:
            p_avg, lg_avg, tp_avg = player_row, avg_calcs[main_position]['lg'], avg_calcs[main_position]['tp']
            rat_lg, rat_tp = rating_series(p_avg, lg_avg), rating_series(p_avg, tp_avg)
            logic_df = logic_flat_df([main_position], logic_data)
            logic_metrics_in_data = [m for m in logic_df["Metric"] if m in rat_lg.index]
            score_lg = weighted_score(rat_lg[logic_metrics_in_data], logic_df)
            player_data = player_row.to_dict()
            player_data['Rating vs Liga'] = score_lg
            sec_lg, sub_lg = breakdown_scores(rat_lg, main_position, logic_data)
            sec_tp, sub_tp = breakdown_scores(rat_tp, main_position, logic_data)
            sec_ratings = sec_lg.rename(columns={"Score": "lg"}).merge(sec_tp.rename(columns={"Score": "tp"}), on="Section", how="outer").to_dict('records')
            sub_ratings = sub_lg.rename(columns={"Score": "lg"}).merge(sub_tp.rename(columns={"Score": "tp"}), on=["Section", "Subsection"], how="outer").to_dict('records')
            player_data['sections'] = sec_ratings
            player_data['subsections'] = sub_ratings
            enriched_results.append(player_data)
    
    return pd.DataFrame(enriched_results)


def prepare_data_for_ai_scout(ratings_df: pd.DataFrame) -> str:
    """P콏evede Obohacen치 data hr치캜콢 na textov칳 form치t pro AI."""
    player_strings = []
    for _, row in ratings_df.iterrows():
        base_info = (
            f"Hr치캜: {row['Player']}, T칳m: {row['Team']}, Sout캩: {row['League']}, Pozice: {row['Converted Position']}, "
            f"V캩k: {row['Age']:.0f}, Noha: {row.get('Foot', 'N/A')}"
        )
        sec_info = ", ".join([ f"{s['Section']}: {s.get('lg', 0):.0f}/{s.get('tp', 0):.0f}" for s in row.get('sections', []) if pd.notna(s.get('lg')) ])
        sub_info = ", ".join([ f"{s['Subsection']}: {s.get('lg', 0):.0f}/{s.get('tp', 0):.0f}" for s in row.get('subsections', []) if pd.notna(s.get('lg')) ])
        
        player_strings.append(f"{base_info}\n  - Sekce -> {sec_info}\n  - Podsekce -> {sub_info}\n---")

    return "\n".join(player_strings)


def run_ai_scout(user_needs: str) -> str:
    """Spust칤 cel칳 proces AI skautingu s obohacen칳mi daty."""
    gemini_model, gemini_available = initialize_gemini()
    if not gemini_available:
        return "Chyba: Slu쬭a Gemini AI nen칤 dostupn치."

    # Na캜ten칤 dat a jejich OBOHACEN칈 pro AI
    all_players_df = load_all_player_data()
    avg_files = list(Path(AVG_DATA_DIR).glob("*.xlsx"))
    all_avg_dfs = [load_and_process_file(file) for file in avg_files]
    combined_avg_df = pd.concat(all_avg_dfs, ignore_index=True)
    avg_df_filtered = combined_avg_df[combined_avg_df["Minutes played"] >= MIN_MINUTES]
    
    # Pou쬴jeme novou funkci pro obohacen칤 dat
    enriched_df = enrich_data_for_ai_scout(all_players_df, avg_df_filtered)

    if enriched_df.empty:
        return "Nenalezena 쮂멳n치 data hr치캜콢 pro anal칳zu."

    # Omezen칤 po캜tu hr치캜콢 pro AI (po코leme TOP 150)
    final_candidates_df = enriched_df.nlargest(500, 'Rating vs Liga')

    # P콏칤prava dat a spu코t캩n칤 AI
    players_data_string = prepare_data_for_ai_scout(final_candidates_df)
    prompt = build_ai_scout_prompt(user_needs, players_data_string)
    
    try:
        msg = Content(role="user", parts=[Part.from_text(prompt)])
        config = GenerationConfig(max_output_tokens=8192, temperature=0.6)
        response = gemini_model.generate_content([msg], generation_config=config)
        return response.text
    except Exception as e:
        return f"Do코lo k chyb캩 p콏i komunikaci s Gemini AI: {e}"
    

def get_custom_comparison(player_series: pd.Series, main_position: str, custom_positions: list, all_avg_df: pd.DataFrame) -> Dict[str, Any]:
    """
    Vypo캜칤t치 srovn치n칤 jednoho hr치캜e v콢캜i pr콢m캩ru vybran칠 skupiny pozic.
    """
    if not custom_positions:
        return {}

    logic_data = get_logic_definition()
    
    # 1. Vytvo콏칤me pr콢m캩r pro vlastn칤 skupinu
    custom_avg_df = all_avg_df[all_avg_df[COL_POS].isin(custom_positions)]
    if custom_avg_df.empty:
        return {"error": "Pro vybran칠 pozice nebyla nalezena 쮂멳n치 srovn치vac칤 data."}
        
    custom_avg = custom_avg_df.groupby("Player").mean(numeric_only=True).mean(numeric_only=True)

    # 2. Provedeme srovn치n칤 (rating, sekce, podsekce)
    rat_custom = rating_series(player_series, custom_avg)
    logic_df = logic_flat_df([main_position], logic_data)
    logic_metrics_in_data = [m for m in logic_df["Metric"] if m in rat_custom.index]
    
    score_custom = weighted_score(rat_custom[logic_metrics_in_data], logic_df)
    sec_custom, sub_custom = breakdown_scores(rat_custom, main_position, logic_data)
    
    # P콏ejmenujeme sloupce pro p콏ehlednost
    sec_tbl = sec_custom.rename(columns={"Score": "vs. Vlastn칤 v칳b캩r"})
    sub_tbl = sub_custom.rename(columns={"Score": "vs. Vlastn칤 v칳b캩r"})

    return {
        "score": score_custom,
        "sec_tbl": sec_tbl,
        "sub_tbl": sub_tbl
    }


def get_player_comparison_data(player1_name: str, player2_name: str, player_df: pd.DataFrame, avg_df: pd.DataFrame) -> Dict[str, Any]:
    """P콏iprav칤 data pro srovn치n칤 dvou hr치캜콢."""
    
    result1 = analyze_player(player1_name, player_df, avg_df)
    result2 = analyze_player(player2_name, player_df, avg_df)

    # Z칤sk치me zkr치cen치 jm칠na pro nadpisy sloupc콢
    p1_name_short = player1_name.split(' ')[-1]
    p2_name_short = player2_name.split(' ')[-1]
    
    # P콏ejmenujeme sloupce s ratingy, aby se daly spojit
    sec_tbl1 = result1["sec_tbl"].rename(columns={"vs. League": f"{p1_name_short} vs. Liga", "vs. TOP 3": f"{p1_name_short} vs. TOP 3"})
    sec_tbl2 = result2["sec_tbl"].rename(columns={"vs. League": f"{p2_name_short} vs. Liga", "vs. TOP 3": f"{p2_name_short} vs. TOP 3"})
    
    sub_tbl1 = result1["sub_tbl"].rename(columns={"vs. League": f"{p1_name_short} vs. Liga", "vs. TOP 3": f"{p1_name_short} vs. TOP 3"})
    sub_tbl2 = result2["sub_tbl"].rename(columns={"vs. League": f"{p2_name_short} vs. Liga", "vs. TOP 3": f"{p2_name_short} vs. TOP 3"})

    # P콏ejmenujeme sloupce s absolutn칤mi hodnotami
    all_m_tbl1 = result1["all_metrics"][['Metric', 'Hr치캜']].rename(columns={"Hr치캜": p1_name_short})
    all_m_tbl2 = result2["all_metrics"][['Metric', 'Hr치캜']].rename(columns={"Hr치캜": p2_name_short})

    # Spoj칤me tabulky
    comparison_sec = pd.merge(sec_tbl1, sec_tbl2, on="Section")
    comparison_sub = pd.merge(sub_tbl1, sub_tbl2, on=["Section", "Subsection"])
    comparison_all = pd.merge(all_m_tbl1, all_m_tbl2, on="Metric")
    
    return {
        "result1": result1,
        "result2": result2,
        "p1_name_short": p1_name_short,
        "p2_name_short": p2_name_short,
        "comparison_sec": comparison_sec,
        "comparison_sub": comparison_sub,
        "comparison_all": comparison_all
    }
